{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application to transactional data\n",
    "\n",
    "Let's apply this to transactional data.\n",
    "\n",
    "### Dataset Description\n",
    "\n",
    "We're going to be using a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail. The original data can be found here: http://archive.ics.uci.edu/ml/datasets/online+retail\n",
    "\n",
    "Let's examine the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1    536365     71053                  WHITE METAL LANTERN         6   \n",
      "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "    InvoiceDate  UnitPrice  CustomerID         Country  \n",
      "0  12/1/10 8:26       2.55     17850.0  United Kingdom  \n",
      "1  12/1/10 8:26       3.39     17850.0  United Kingdom  \n",
      "2  12/1/10 8:26       2.75     17850.0  United Kingdom  \n",
      "3  12/1/10 8:26       3.39     17850.0  United Kingdom  \n",
      "4  12/1/10 8:26       3.39     17850.0  United Kingdom  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('Online Retail.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Dataset provider\n",
    "\n",
    "Now let's format the data for the Autoencoder to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Session ID    Item ID  Quantity\n",
      "0          11  214821376         2\n",
      "1          12  214717872         4\n",
      "2          21  214548736         1\n",
      "3          21  214838496         1\n",
      "4          33  214706448         2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Filter excessive positive and negative quantities\n",
    "mask_1 = df['Quantity'] > 0\n",
    "mask_2 = df['Quantity'] < 30\n",
    "df = df[np.logical_and(mask_1, mask_2)]\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "df['ItemID'] = le.fit_transform(df['StockCode'])\n",
    "\n",
    "# Process datetime\n",
    "df['Date'] = pd.to_datetime(df['InvoiceDate'])\n",
    "\n",
    "# Split into train and test\n",
    "mask = df['Date'] < pd.to_datetime('2011-11-01')\n",
    "print(mask.sum() / len(mask))\n",
    "df_train = df[mask]\n",
    "df_test = df[np.logical_not(mask)]\n",
    "\n",
    "# Aggregate to session and item level\n",
    "ids = ['CustomerID', 'ItemID']\n",
    "df_train_agg = df_train[ids + ['Quantity']].groupby(ids).sum()\n",
    "df_train_agg = df_train_agg.reset_index().sort_values(ids)\n",
    "df_test_agg = df_test[ids + ['Quantity']].groupby(ids).sum()\n",
    "df_test_agg = df_test_agg.reset_index().sort_values(ids)\n",
    "\n",
    "# Process columns from float to int\n",
    "df_train_agg['CustomerID'] = df_train_agg['CustomerID'].astype(np.int)\n",
    "df_test_agg['CustomerID'] = df_test_agg['CustomerID'].astype(np.int)\n",
    "\n",
    "# Process quantity\n",
    "df_train_agg['Quantity'] = 1 * (df_train_agg['Quantity'] >= 1)\n",
    "df_test_agg['Quantity'] = 1 * (df_test_agg['Quantity'] >= 1)\n",
    "\n",
    "# Remove users and items that aren't in training set\n",
    "mask_3 = np.in1d(df_test_agg['CustomerID'], df_train_agg['CustomerID'])\n",
    "mask_4 = np.in1d(df_test_agg['ItemID'], df_train_agg['ItemID'])\n",
    "df_test_agg = df_test_agg[np.logical_and(mask_3, mask_4)]\n",
    "\n",
    "# Write data\n",
    "folders = ['retail/TRAIN', 'retail/TEST']\n",
    "for folder in folders:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "df_train_agg.to_csv('retail/TRAIN/train.txt', sep='\\t',\n",
    "                    header=False, index=False)\n",
    "df_test_agg.to_csv('retail/TEST/test.txt', sep='\\t',\n",
    "                   header=False, index=False)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12347\t29\t1\r\n",
      "12347\t130\t1\r\n",
      "12347\t167\t1\r\n",
      "12347\t207\t1\r\n",
      "12347\t209\t1\r\n",
      "12347\t281\t1\r\n",
      "12347\t323\t1\r\n",
      "12347\t327\t1\r\n",
      "12347\t340\t1\r\n",
      "12347\t392\t1\r\n"
     ]
    }
   ],
   "source": [
    "!head retail/TRAIN/train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12347\t167\t1\r\n",
      "12347\t340\t1\r\n",
      "12347\t473\t1\r\n",
      "12347\t770\t1\r\n",
      "12347\t1939\t1\r\n",
      "12347\t2113\t1\r\n",
      "12347\t2323\t1\r\n",
      "12347\t2332\t1\r\n",
      "12347\t2334\t1\r\n",
      "12347\t3052\t1\r\n"
     ]
    }
   ],
   "source": [
    "!head retail/TEST/test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment and results\n",
    "\n",
    "To be edited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(aug_step=1, batch_size=128, constrained=False, drop_prob=0.8, gpu_ids='0', hidden_layers='512,512,1024', logdir='model_save', lr=0.005, noise_prob=0.0, non_linearity_type='selu', num_epochs=50, optimizer='momentum', path_to_eval_data='retail/TEST', path_to_train_data='retail/TRAIN', skip_last_layer_nl=False, summary_frequency=500, weight_decay=0.0)\n",
      "Loading training data\n",
      "Data loaded\n",
      "Total items found: 3879\n",
      "Vector dim: 3596\n",
      "Loading eval data\n",
      "******************************\n",
      "******************************\n",
      "[3596, 512, 512, 1024]\n",
      "Dropout drop probability: 0.8\n",
      "Encoder pass:\n",
      "torch.Size([512, 3596])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([1024, 512])\n",
      "torch.Size([1024])\n",
      "Decoder pass:\n",
      "torch.Size([512, 1024])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([3596, 512])\n",
      "torch.Size([3596])\n",
      "******************************\n",
      "******************************\n",
      "######################################################\n",
      "######################################################\n",
      "############# AutoEncoder Model: #####################\n",
      "AutoEncoder(\n",
      "  (drop): Dropout(p=0.8)\n",
      "  (encode_w): ParameterList(\n",
      "  )\n",
      "  (encode_b): ParameterList(\n",
      "  )\n",
      "  (decode_w): ParameterList(\n",
      "  )\n",
      "  (decode_b): ParameterList(\n",
      "  )\n",
      ")\n",
      "######################################################\n",
      "######################################################\n",
      "Using GPUs: [0]\n",
      "Doing epoch 0 of 50\n",
      "[0,     0] RMSE: 1.1872617\n",
      "Total epoch 0 finished in 0.49122142791748047 seconds with TRAINING RMSE loss: 1.1441986451307273\n",
      "Epoch 0 EVALUATION LOSS: 0.9526005800133328\n",
      "Saving model to model_save/model.epoch_0\n",
      "Doing epoch 1 of 50\n",
      "[1,     0] RMSE: 1.1401667\n",
      "Total epoch 1 finished in 0.2747640609741211 seconds with TRAINING RMSE loss: 0.9444559509536311\n",
      "Doing epoch 2 of 50\n",
      "[2,     0] RMSE: 0.9356835\n",
      "Total epoch 2 finished in 0.2737996578216553 seconds with TRAINING RMSE loss: 0.7123021648652748\n",
      "Doing epoch 3 of 50\n",
      "[3,     0] RMSE: 0.7058163\n",
      "Total epoch 3 finished in 0.27469635009765625 seconds with TRAINING RMSE loss: 0.5715804745194373\n",
      "Epoch 3 EVALUATION LOSS: 0.41882773763095216\n",
      "Saving model to model_save/model.epoch_3\n",
      "Doing epoch 4 of 50\n",
      "[4,     0] RMSE: 0.5682912\n",
      "Total epoch 4 finished in 0.28667140007019043 seconds with TRAINING RMSE loss: 0.49162848076459875\n",
      "Doing epoch 5 of 50\n",
      "[5,     0] RMSE: 0.4904929\n",
      "Total epoch 5 finished in 0.27303051948547363 seconds with TRAINING RMSE loss: 0.4383978729892488\n",
      "Doing epoch 6 of 50\n",
      "[6,     0] RMSE: 0.4366699\n",
      "Total epoch 6 finished in 0.275557279586792 seconds with TRAINING RMSE loss: 0.39849103804777214\n",
      "Epoch 6 EVALUATION LOSS: 0.2553055084106185\n",
      "Saving model to model_save/model.epoch_6\n",
      "Doing epoch 7 of 50\n",
      "[7,     0] RMSE: 0.3969672\n",
      "Total epoch 7 finished in 0.27106428146362305 seconds with TRAINING RMSE loss: 0.36679160067253525\n",
      "Doing epoch 8 of 50\n",
      "[8,     0] RMSE: 0.3667498\n",
      "Total epoch 8 finished in 0.2693901062011719 seconds with TRAINING RMSE loss: 0.34254875571929694\n",
      "Doing epoch 9 of 50\n",
      "[9,     0] RMSE: 0.3413637\n",
      "Total epoch 9 finished in 0.2709221839904785 seconds with TRAINING RMSE loss: 0.32229456607835294\n",
      "Epoch 9 EVALUATION LOSS: 0.18658809007717836\n",
      "Saving model to model_save/model.epoch_9\n",
      "Doing epoch 10 of 50\n",
      "[10,     0] RMSE: 0.3214147\n",
      "Total epoch 10 finished in 0.2763102054595947 seconds with TRAINING RMSE loss: 0.30470503976661484\n",
      "Doing epoch 11 of 50\n",
      "[11,     0] RMSE: 0.3041845\n",
      "Total epoch 11 finished in 0.27414774894714355 seconds with TRAINING RMSE loss: 0.2921308483785162\n",
      "Doing epoch 12 of 50\n",
      "[12,     0] RMSE: 0.2913888\n",
      "Total epoch 12 finished in 0.2694981098175049 seconds with TRAINING RMSE loss: 0.2788326803070257\n",
      "Epoch 12 EVALUATION LOSS: 0.1529893813919695\n",
      "Saving model to model_save/model.epoch_12\n",
      "Doing epoch 13 of 50\n",
      "[13,     0] RMSE: 0.2788036\n",
      "Total epoch 13 finished in 0.26926302909851074 seconds with TRAINING RMSE loss: 0.26693970704660464\n",
      "Doing epoch 14 of 50\n",
      "[14,     0] RMSE: 0.2666929\n",
      "Total epoch 14 finished in 0.27383923530578613 seconds with TRAINING RMSE loss: 0.2582159586942576\n",
      "Doing epoch 15 of 50\n",
      "[15,     0] RMSE: 0.2580118\n",
      "Total epoch 15 finished in 0.2736928462982178 seconds with TRAINING RMSE loss: 0.24845592257533194\n",
      "Epoch 15 EVALUATION LOSS: 0.1360058634735294\n",
      "Saving model to model_save/model.epoch_15\n",
      "Doing epoch 16 of 50\n",
      "[16,     0] RMSE: 0.2480940\n",
      "Total epoch 16 finished in 0.27392029762268066 seconds with TRAINING RMSE loss: 0.24092359120076243\n",
      "Doing epoch 17 of 50\n",
      "[17,     0] RMSE: 0.2406436\n",
      "Total epoch 17 finished in 0.27317142486572266 seconds with TRAINING RMSE loss: 0.2349195942875316\n",
      "Doing epoch 18 of 50\n",
      "[18,     0] RMSE: 0.2349760\n",
      "Total epoch 18 finished in 0.27442240715026855 seconds with TRAINING RMSE loss: 0.22855326350708477\n",
      "Epoch 18 EVALUATION LOSS: 0.12175650399066996\n",
      "Saving model to model_save/model.epoch_18\n",
      "Doing epoch 19 of 50\n",
      "[19,     0] RMSE: 0.2282210\n",
      "Total epoch 19 finished in 0.2768881320953369 seconds with TRAINING RMSE loss: 0.22368761360117254\n",
      "Doing epoch 20 of 50\n",
      "[20,     0] RMSE: 0.2236757\n",
      "Total epoch 20 finished in 0.27063894271850586 seconds with TRAINING RMSE loss: 0.21905408880063812\n",
      "Doing epoch 21 of 50\n",
      "[21,     0] RMSE: 0.2188310\n",
      "Total epoch 21 finished in 0.274172306060791 seconds with TRAINING RMSE loss: 0.21579576585741628\n",
      "Epoch 21 EVALUATION LOSS: 0.1131839962062621\n",
      "Saving model to model_save/model.epoch_21\n",
      "Doing epoch 22 of 50\n",
      "[22,     0] RMSE: 0.2157885\n",
      "Total epoch 22 finished in 0.2719268798828125 seconds with TRAINING RMSE loss: 0.21019441531049585\n",
      "Doing epoch 23 of 50\n",
      "[23,     0] RMSE: 0.2101114\n",
      "Total epoch 23 finished in 0.2693042755126953 seconds with TRAINING RMSE loss: 0.20560379473598817\n",
      "Doing epoch 24 of 50\n",
      "[24,     0] RMSE: 0.2049001\n",
      "Total epoch 24 finished in 0.2740504741668701 seconds with TRAINING RMSE loss: 0.20330310495869824\n",
      "Epoch 24 EVALUATION LOSS: 0.10682531208150231\n",
      "Saving model to model_save/model.epoch_24\n",
      "Doing epoch 25 of 50\n",
      "[25,     0] RMSE: 0.2034953\n",
      "Total epoch 25 finished in 0.2735159397125244 seconds with TRAINING RMSE loss: 0.20102909447012327\n",
      "Doing epoch 26 of 50\n",
      "[26,     0] RMSE: 0.2010379\n",
      "Total epoch 26 finished in 0.27199649810791016 seconds with TRAINING RMSE loss: 0.19938135897053266\n",
      "Doing epoch 27 of 50\n",
      "[27,     0] RMSE: 0.1993668\n",
      "Total epoch 27 finished in 0.273029088973999 seconds with TRAINING RMSE loss: 0.19776830455968683\n",
      "Epoch 27 EVALUATION LOSS: 0.10519169128490993\n",
      "Saving model to model_save/model.epoch_27\n",
      "Doing epoch 28 of 50\n",
      "[28,     0] RMSE: 0.1982892\n",
      "Total epoch 28 finished in 0.267958402633667 seconds with TRAINING RMSE loss: 0.19749143788131446\n",
      "Doing epoch 29 of 50\n",
      "[29,     0] RMSE: 0.1966122\n",
      "Total epoch 29 finished in 0.27090883255004883 seconds with TRAINING RMSE loss: 0.19522830165510882\n",
      "Doing epoch 30 of 50\n",
      "[30,     0] RMSE: 0.1956102\n",
      "Total epoch 30 finished in 0.2755422592163086 seconds with TRAINING RMSE loss: 0.19381034101161\n",
      "Epoch 30 EVALUATION LOSS: 0.10217524982324538\n",
      "Saving model to model_save/model.epoch_30\n",
      "Doing epoch 31 of 50\n",
      "[31,     0] RMSE: 0.1935441\n",
      "Total epoch 31 finished in 0.2711319923400879 seconds with TRAINING RMSE loss: 0.19191926209564716\n",
      "Doing epoch 32 of 50\n",
      "[32,     0] RMSE: 0.1920529\n",
      "Total epoch 32 finished in 0.27288150787353516 seconds with TRAINING RMSE loss: 0.19102249487450249\n",
      "Doing epoch 33 of 50\n",
      "[33,     0] RMSE: 0.1906747\n",
      "Total epoch 33 finished in 0.2727375030517578 seconds with TRAINING RMSE loss: 0.18909355843093584\n",
      "Epoch 33 EVALUATION LOSS: 0.09924582897484635\n",
      "Saving model to model_save/model.epoch_33\n",
      "Doing epoch 34 of 50\n",
      "[34,     0] RMSE: 0.1891148\n",
      "Total epoch 34 finished in 0.2731361389160156 seconds with TRAINING RMSE loss: 0.1875986134631949\n",
      "Doing epoch 35 of 50\n",
      "[35,     0] RMSE: 0.1877658\n",
      "Total epoch 35 finished in 0.27077698707580566 seconds with TRAINING RMSE loss: 0.18724371411900553\n",
      "Doing epoch 36 of 50\n",
      "[36,     0] RMSE: 0.1870426\n",
      "Total epoch 36 finished in 0.2721407413482666 seconds with TRAINING RMSE loss: 0.1857093514594343\n",
      "Epoch 36 EVALUATION LOSS: 0.09811182175386587\n",
      "Saving model to model_save/model.epoch_36\n",
      "Doing epoch 37 of 50\n",
      "[37,     0] RMSE: 0.1856876\n",
      "Total epoch 37 finished in 0.2728910446166992 seconds with TRAINING RMSE loss: 0.18512072078099\n",
      "Doing epoch 38 of 50\n",
      "[38,     0] RMSE: 0.1850815\n",
      "Total epoch 38 finished in 0.2707962989807129 seconds with TRAINING RMSE loss: 0.1839408257043145\n",
      "Doing epoch 39 of 50\n",
      "[39,     0] RMSE: 0.1840880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total epoch 39 finished in 0.270003080368042 seconds with TRAINING RMSE loss: 0.18442396016310184\n",
      "Epoch 39 EVALUATION LOSS: 0.09746190868051324\n",
      "Saving model to model_save/model.epoch_39\n",
      "Doing epoch 40 of 50\n",
      "[40,     0] RMSE: 0.1841024\n",
      "Total epoch 40 finished in 0.2738964557647705 seconds with TRAINING RMSE loss: 0.18297309379921387\n",
      "Doing epoch 41 of 50\n",
      "[41,     0] RMSE: 0.1830710\n",
      "Total epoch 41 finished in 0.27388429641723633 seconds with TRAINING RMSE loss: 0.18248006582122078\n",
      "Doing epoch 42 of 50\n",
      "[42,     0] RMSE: 0.1824773\n",
      "Total epoch 42 finished in 0.2709999084472656 seconds with TRAINING RMSE loss: 0.18187371649240078\n",
      "Epoch 42 EVALUATION LOSS: 0.09670318491883391\n",
      "Saving model to model_save/model.epoch_42\n",
      "Doing epoch 43 of 50\n",
      "[43,     0] RMSE: 0.1822296\n",
      "Total epoch 43 finished in 0.274259090423584 seconds with TRAINING RMSE loss: 0.18156921818708208\n",
      "Doing epoch 44 of 50\n",
      "[44,     0] RMSE: 0.1816645\n",
      "Total epoch 44 finished in 0.2700827121734619 seconds with TRAINING RMSE loss: 0.1828755831966088\n",
      "Doing epoch 45 of 50\n",
      "[45,     0] RMSE: 0.1820575\n",
      "Total epoch 45 finished in 0.26932477951049805 seconds with TRAINING RMSE loss: 0.18195082776874463\n",
      "Epoch 45 EVALUATION LOSS: 0.09555481831645767\n",
      "Saving model to model_save/model.epoch_45\n",
      "Doing epoch 46 of 50\n",
      "[46,     0] RMSE: 0.1826369\n",
      "Total epoch 46 finished in 0.27836179733276367 seconds with TRAINING RMSE loss: 0.17944325211363893\n",
      "Doing epoch 47 of 50\n",
      "[47,     0] RMSE: 0.1794154\n",
      "Total epoch 47 finished in 0.2701914310455322 seconds with TRAINING RMSE loss: 0.1797751449637712\n",
      "Doing epoch 48 of 50\n",
      "[48,     0] RMSE: 0.1794199\n",
      "Total epoch 48 finished in 0.2711963653564453 seconds with TRAINING RMSE loss: 0.17937624482864875\n",
      "Epoch 48 EVALUATION LOSS: 0.09436344764661621\n",
      "Saving model to model_save/model.epoch_48\n",
      "Doing epoch 49 of 50\n",
      "[49,     0] RMSE: 0.1794716\n",
      "Total epoch 49 finished in 0.27149176597595215 seconds with TRAINING RMSE loss: 0.17951782325063648\n",
      "Epoch 49 EVALUATION LOSS: 0.09381776962985272\n",
      "Saving model to model_save/model.epoch_49\n",
      "Saving model to model_save/model.last\n"
     ]
    }
   ],
   "source": [
    "!python run.py --gpu_ids 0 \\\n",
    "--path_to_train_data retail/TRAIN \\\n",
    "--path_to_eval_data retail/TEST \\\n",
    "--hidden_layers 512,512,1024 \\\n",
    "--non_linearity_type selu \\\n",
    "--batch_size 128 \\\n",
    "--logdir model_save \\\n",
    "--drop_prob 0.8 \\\n",
    "--optimizer momentum \\\n",
    "--lr 0.005 \\\n",
    "--weight_decay 0 \\\n",
    "--aug_step 1 \\\n",
    "--noise_prob 0 \\\n",
    "--num_epochs 50 \\\n",
    "--summary_frequency 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard 1.5.0 at http://432008e1172c:6006 (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=model_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf model_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(constrained=False, drop_prob=0.8, hidden_layers='512,512,1024', non_linearity_type='selu', path_to_eval_data='retail/TRAIN', path_to_train_data='retail/TRAIN', predictions_path='preds_train.txt', save_path='model_save/model.epoch_49', skip_last_layer_nl=False)\n",
      "Loading training data\n",
      "Data loaded\n",
      "Total items found: 3879\n",
      "Vector dim: 3596\n",
      "Loading eval data\n",
      "******************************\n",
      "******************************\n",
      "[3596, 512, 512, 1024]\n",
      "Dropout drop probability: 0.8\n",
      "Encoder pass:\n",
      "torch.Size([512, 3596])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([1024, 512])\n",
      "torch.Size([1024])\n",
      "Decoder pass:\n",
      "torch.Size([512, 1024])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([3596, 512])\n",
      "torch.Size([3596])\n",
      "******************************\n",
      "******************************\n",
      "Loading model from: model_save/model.epoch_49\n",
      "######################################################\n",
      "######################################################\n",
      "############# AutoEncoder Model: #####################\n",
      "AutoEncoder(\n",
      "  (drop): Dropout(p=0.8)\n",
      "  (encode_w): ParameterList(\n",
      "  )\n",
      "  (encode_b): ParameterList(\n",
      "  )\n",
      "  (decode_w): ParameterList(\n",
      "  )\n",
      "  (decode_b): ParameterList(\n",
      "  )\n",
      ")\n",
      "######################################################\n",
      "######################################################\n",
      "Done: 0\n"
     ]
    }
   ],
   "source": [
    "!python infer.py \\\n",
    "--path_to_train_data retail/TRAIN \\\n",
    "--path_to_eval_data retail/TEST \\\n",
    "--hidden_layers 512,512,1024 \\\n",
    "--non_linearity_type selu \\\n",
    "--save_path model_save/model.epoch_49 \\\n",
    "--drop_prob 0.8 \\\n",
    "--predictions_path preds.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12347\t29\t1.0022114515304565\t1.0\r\n",
      "12347\t130\t1.0056113004684448\t1.0\r\n",
      "12347\t167\t1.0526694059371948\t1.0\r\n",
      "12347\t207\t1.2262483835220337\t1.0\r\n",
      "12347\t209\t1.0388710498809814\t1.0\r\n",
      "12347\t281\t1.0841541290283203\t1.0\r\n",
      "12347\t323\t1.0782625675201416\t1.0\r\n",
      "12347\t327\t1.1885783672332764\t1.0\r\n",
      "12347\t340\t1.000394344329834\t1.0\r\n",
      "12347\t392\t1.061516284942627\t1.0\r\n",
      "12347\t407\t1.1897742748260498\t1.0\r\n",
      "12347\t473\t1.1478164196014404\t1.0\r\n",
      "12347\t661\t1.0947186946868896\t1.0\r\n",
      "12347\t697\t1.000368356704712\t1.0\r\n",
      "12347\t770\t1.0166997909545898\t1.0\r\n",
      "12347\t806\t1.039190649986267\t1.0\r\n",
      "12347\t837\t0.9917394518852234\t1.0\r\n",
      "12347\t926\t1.0237293243408203\t1.0\r\n",
      "12347\t927\t1.0889842510223389\t1.0\r\n",
      "12347\t1047\t1.0912761688232422\t1.0\r\n",
      "12347\t1050\t1.0489686727523804\t1.0\r\n",
      "12347\t1105\t0.9916511178016663\t1.0\r\n",
      "12347\t1106\t1.1202387809753418\t1.0\r\n",
      "12347\t1121\t0.9663246273994446\t1.0\r\n",
      "12347\t1152\t1.131880760192871\t1.0\r\n",
      "12347\t1262\t1.097755789756775\t1.0\r\n",
      "12347\t1263\t0.9538242816925049\t1.0\r\n",
      "12347\t1264\t0.9588323831558228\t1.0\r\n",
      "12347\t1265\t1.0248124599456787\t1.0\r\n",
      "12347\t1266\t1.1357598304748535\t1.0\r\n",
      "12347\t1301\t1.048879861831665\t1.0\r\n",
      "12347\t1306\t0.9963939189910889\t1.0\r\n",
      "12347\t1307\t0.9896243214607239\t1.0\r\n",
      "12347\t1316\t1.0099914073944092\t1.0\r\n",
      "12347\t1373\t1.0383862257003784\t1.0\r\n",
      "12347\t1376\t1.1076273918151855\t1.0\r\n",
      "12347\t1426\t1.017406702041626\t1.0\r\n",
      "12347\t1436\t1.1229840517044067\t1.0\r\n",
      "12347\t1494\t1.0396201610565186\t1.0\r\n",
      "12347\t1567\t1.0006978511810303\t1.0\r\n",
      "12347\t1568\t1.0285102128982544\t1.0\r\n",
      "12347\t1569\t1.0270600318908691\t1.0\r\n",
      "12347\t1594\t1.1501213312149048\t1.0\r\n",
      "12347\t1595\t0.9158810973167419\t1.0\r\n",
      "12347\t1596\t1.1046652793884277\t1.0\r\n",
      "12347\t1597\t0.9820536971092224\t1.0\r\n",
      "12347\t1598\t1.0484070777893066\t1.0\r\n",
      "12347\t1640\t1.067029595375061\t1.0\r\n",
      "12347\t1641\t1.0945398807525635\t1.0\r\n",
      "12347\t1642\t1.0997987985610962\t1.0\r\n"
     ]
    }
   ],
   "source": [
    "!head preds_train.txt -n 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12347\t167\t1\r\n",
      "12347\t340\t1\r\n",
      "12347\t473\t1\r\n",
      "12347\t770\t1\r\n",
      "12347\t1939\t1\r\n",
      "12347\t2113\t1\r\n",
      "12347\t2323\t1\r\n",
      "12347\t2332\t1\r\n",
      "12347\t2334\t1\r\n",
      "12347\t3052\t1\r\n",
      "12352\t720\t1\r\n",
      "12352\t1088\t1\r\n",
      "12352\t1497\t1\r\n",
      "12352\t1500\t1\r\n",
      "12352\t1508\t1\r\n",
      "12352\t1538\t1\r\n",
      "12352\t1839\t1\r\n",
      "12352\t1843\t1\r\n",
      "12352\t1943\t1\r\n",
      "12352\t1944\t1\r\n"
     ]
    }
   ],
   "source": [
    "!head retail/TEST/test.txt -n 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12347\t167\t1.0526694059371948\t1.0\r\n",
      "12347\t340\t1.000394344329834\t1.0\r\n",
      "12347\t473\t1.1478164196014404\t1.0\r\n",
      "12347\t770\t1.0166997909545898\t1.0\r\n",
      "12347\t1939\t0.9950699806213379\t1.0\r\n",
      "12347\t2332\t1.1410807371139526\t1.0\r\n",
      "12347\t2334\t1.1010527610778809\t1.0\r\n",
      "12347\t3052\t1.010302186012268\t1.0\r\n",
      "12347\t2113\t1.0811024904251099\t1.0\r\n",
      "12347\t2323\t0.9664358496665955\t1.0\r\n",
      "12352\t3918\t0.987004280090332\t1.0\r\n",
      "12352\t1497\t0.987648606300354\t1.0\r\n",
      "12352\t1508\t1.1000040769577026\t1.0\r\n",
      "12352\t1538\t1.0199328660964966\t1.0\r\n",
      "12352\t1500\t1.0147424936294556\t1.0\r\n",
      "12352\t1843\t0.9649232029914856\t1.0\r\n",
      "12352\t720\t1.0109050273895264\t1.0\r\n",
      "12352\t2385\t1.102394938468933\t1.0\r\n",
      "12352\t1839\t1.0148576498031616\t1.0\r\n",
      "12352\t1088\t0.9791996479034424\t1.0\r\n"
     ]
    }
   ],
   "source": [
    "!head preds.txt -n 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(path_to_predictions='preds.txt', round=False)\n",
      "####################\n",
      "RMSE: 0.09381776951434737\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "!python compute_RMSE.py --path_to_predictions=preds.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(path_to_predictions='preds_train.txt', round=False)\n",
      "####################\n",
      "RMSE: 0.0901337912503639\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "!python compute_RMSE.py --path_to_predictions=preds_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from reco_encoder.data import input_layer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all data\n"
     ]
    }
   ],
   "source": [
    "params = dict()\n",
    "params['batch_size'] = 128\n",
    "params['data_dir'] = 'yoochoose-data/ALL'\n",
    "params['major'] = 'users'\n",
    "params['itemIdInd'] = 1\n",
    "params['userIdInd'] = 0\n",
    "print(\"Loading all data\")\n",
    "all_data_layer = input_layer.UserItemRecDataProvider(params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading training data\")\n",
    "train_params = copy.deepcopy(params)\n",
    "params['data_dir'] = 'yoochoose-data/TRAIN'\n",
    "data_layer = input_layer.UserItemRecDataProvider(params=train_params, \n",
    "                                                 user_id_map=all_data_layer.userIdMap, \n",
    "                                                 item_id_map=all_data_layer.itemIdMap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_params = copy.deepcopy(train_params)\n",
    "eval_params['data_dir'] = 'yoochoose-data/TEST'\n",
    "data_layer_eval = input_layer.UserItemRecDataProvider(params=eval_params, \n",
    "                                                      user_id_map=all_data_layer.userIdMap, \n",
    "                                                      item_id_map=all_data_layer.itemIdMap)\n",
    "data_layer_eval.src_data = data_layer.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FloatTensor of size 128x7025 with indices:\n",
       "\n",
       "\n",
       "Columns 0 to 12 \n",
       "    0     1     2     3     3     4     5     5     5     5     6     6     6\n",
       "  799  1036   669    50  1693   143    11   738  1062    59   646   782   146\n",
       "\n",
       "Columns 13 to 25 \n",
       "    6     7     8     8     9     9     9    10    10    11    11    12    13\n",
       "   89  3229  1622   717   156   827    79   416   135  1610   848   510   329\n",
       "\n",
       "Columns 26 to 38 \n",
       "   14    15    16    16    16    17    18    18    19    20    20    20    20\n",
       "  629     6  2389  1584   288   188    27    80  1551    95  3735  4962   286\n",
       "\n",
       "Columns 39 to 51 \n",
       "   20    20    20    21    21    22    22    23    24    25    25    26    27\n",
       "    4   195  1075  2364  1940    23    68   224   877   770  1020   470   255\n",
       "\n",
       "Columns 52 to 64 \n",
       "   27    28    29    29    30    31    31    32    33    34    34    35    36\n",
       "  302   364  1399  1103    29  1964   720    56  2733  2448   194  2898  3174\n",
       "\n",
       "Columns 65 to 77 \n",
       "   37    37    38    38    39    40    40    40    40    40    40    41    41\n",
       "   11   167   156   265  1303    28   171   650   646   300   248   117    19\n",
       "\n",
       "Columns 78 to 90 \n",
       "   41    42    42    42    43    44    44    44    45    45    46    46    46\n",
       "  589   358    28   105   565    91   894   498   586   549   237   650   318\n",
       "\n",
       "Columns 91 to 103 \n",
       "   46    47    47    47    48    49    49    50    50    50    50    50    51\n",
       "   26   199   174    78   554   125   445    21    87   348   401    27   306\n",
       "\n",
       "Columns 104 to 116 \n",
       "   51    51    52    53    53    53    53    54    55    56    57    58    59\n",
       " 1027   206   117  2069    45   335   106    97  1737   162   618    14   329\n",
       "\n",
       "Columns 117 to 129 \n",
       "   60    61    61    61    61    62    62    62    62    62    63    63    64\n",
       "  504   965    72   321   104   147   334   175   158   330    19   536     6\n",
       "\n",
       "Columns 130 to 142 \n",
       "   65    65    66    66    67    68    68    68    69    69    69    70    70\n",
       "  160   394   327   409    85   847    95   184   224    19   229  1030   135\n",
       "\n",
       "Columns 143 to 155 \n",
       "   70    71    72    73    74    74    74    75    75    75    75    76    76\n",
       "  192   380   697  3055  1587    20   367   125   400   124   158   170   293\n",
       "\n",
       "Columns 156 to 168 \n",
       "   76    76    77    78    79    80    81    81    82    82    83    83    83\n",
       "  868   401   202     6   761   770    28   171    19   117  1596   551   285\n",
       "\n",
       "Columns 169 to 181 \n",
       "   84    85    85    85    86    87    88    88    88    89    90    91    91\n",
       "  444  3378  5046   334   423  1619   127   763   340  2468  1148    97  3139\n",
       "\n",
       "Columns 182 to 194 \n",
       "   92    92    92    93    93    93    94    94    94    94    95    96    96\n",
       "  103   214  4069   599   335   396   215  3179  1042   420   253   166   127\n",
       "\n",
       "Columns 195 to 207 \n",
       "   97    98    98    98    99   100   100   101   101   102   102   102   102\n",
       " 1068    77    79    50    56   394   160   467   113  2436   199   871   812\n",
       "\n",
       "Columns 208 to 220 \n",
       "  103   103   104   105   106   106   106   107   107   107   108   108   109\n",
       "  870   195    87   346   265   792   527    21    87   178  1720   485    98\n",
       "\n",
       "Columns 221 to 233 \n",
       "  109   110   110   110   111   111   112   112   113   113   114   114   115\n",
       "    2    31   729   171  1534   434   301    55    87    10   340  1995   335\n",
       "\n",
       "Columns 234 to 246 \n",
       "  115   116   116   117   118   119   120   120   121   122   123   123   124\n",
       "  953  2891  1620   686   335  1803  2513   374    54    54   364   468   953\n",
       "\n",
       "Columns 247 to 254 \n",
       "  124   125   125   126   127   127   127   127\n",
       "  142   782   414     9   542   902  1396   409\n",
       "[torch.LongTensor of size 2x255]\n",
       "and values:\n",
       "\n",
       "  0\n",
       "  1\n",
       "  1\n",
       "  0\n",
       "  0\n",
       "  7\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  3\n",
       "  1\n",
       "  2\n",
       "  1\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  1\n",
       "  1\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  1\n",
       "  0\n",
       "  0\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       " 12\n",
       " 24\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  1\n",
       "  4\n",
       "  4\n",
       "  3\n",
       "  0\n",
       "  0\n",
       "  1\n",
       "  0\n",
       "  0\n",
       "  4\n",
       "  2\n",
       "  2\n",
       "  1\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  1\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  3\n",
       "  1\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  1\n",
       "  1\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  0\n",
       "  0\n",
       "  1\n",
       "  2\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  1\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  1\n",
       "  2\n",
       "  2\n",
       "  2\n",
       "  4\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  2\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  0\n",
       "  0\n",
       "  1\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  2\n",
       "  1\n",
       "  1\n",
       "  2\n",
       "  1\n",
       "  1\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  2\n",
       "  1\n",
       "  1\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  1\n",
       "  1\n",
       "  3\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  3\n",
       "  0\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  3\n",
       "  1\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  2\n",
       "  2\n",
       "  1\n",
       "  1\n",
       "  8\n",
       "  4\n",
       "  3\n",
       "  3\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  2\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  1\n",
       "  1\n",
       "  0\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "[torch.FloatTensor of size 255]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(data_layer.iterate_one_epoch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(FloatTensor of size 1x7025 with indices:\n",
       " \n",
       "    0    0\n",
       "  159   19\n",
       " [torch.LongTensor of size 2x2]\n",
       " and values:\n",
       " \n",
       "  0\n",
       "  0\n",
       " [torch.FloatTensor of size 2], FloatTensor of size 1x7025 with indices:\n",
       " \n",
       "    0    0    0\n",
       "  117  159   19\n",
       " [torch.LongTensor of size 2x3]\n",
       " and values:\n",
       " \n",
       "  0\n",
       "  0\n",
       "  0\n",
       " [torch.FloatTensor of size 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(data_layer_eval.iterate_one_epoch_eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict()\n",
    "params['batch_size'] = 128\n",
    "params['data_dir'] = 'yoochoose-data/ALL'\n",
    "params['major'] = 'users'\n",
    "params['itemIdInd'] = 1\n",
    "params['userIdInd'] = 0\n",
    "print(\"Loading all data\")\n",
    "all_data_layer = input_layer.UserItemRecDataProvider(params=params)\n",
    "print(\"Loading training data\")\n",
    "train_params = copy.deepcopy(params)\n",
    "params['data_dir'] = 'yoochoose-data/TRAIN'\n",
    "data_layer = input_layer.UserItemRecDataProvider(params=train_params, \n",
    "                                                 user_id_map=all_data_layer.userIdMap, \n",
    "                                                 item_id_map=all_data_layer.itemIdMap)\n",
    "eval_params = copy.deepcopy(train_params)\n",
    "eval_params['data_dir'] = 'yoochoose-data/TEST'\n",
    "data_layer_eval = input_layer.UserItemRecDataProvider(params=eval_params, \n",
    "                                                      user_id_map=all_data_layer.userIdMap, \n",
    "                                                      item_id_map=all_data_layer.itemIdMap)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
